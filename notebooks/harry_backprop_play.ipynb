{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# horsing around with the backprop algorithm\n",
    "Marcus started this see how quickly he could get backprop to stand up.\n",
    "\n",
    "Note the use of \"checkgrad\", which exhaustively confirms that the gradient calculation is in fact correct - not something to run all the time but a useful check to have.\n",
    "\n",
    "Issues:\n",
    "  * the neural net has no biases yet\n",
    "  * the learning problem is just random - better if we could read in a training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import sklearn\n",
    "import sklearn.datasets as ds\n",
    "import sklearn.cross_validation as cv\n",
    "import sklearn.neighbors as nb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision = 2, suppress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify some neuron transfer functions and their derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(phi):\n",
    "    \"\"\"Calculates the sigmoid of phi.\n",
    "    \n",
    "    phi - A matrix of weighted inputs i.e. np.dot(W, X).\n",
    "    \"\"\"\n",
    "    neg_phi = -1 * phi\n",
    "    \n",
    "    return (1.0 / (1.0 + np.exp(neg_phi)))\n",
    "\n",
    "def grad_sigmoid(x):\n",
    "    \"\"\"Calculates the gradient of the sigmoid function at point x. Note that\n",
    "    this is hard coded to correspond directly to the sigmoid(phi) function\n",
    "    above.\n",
    "    \n",
    "    x - The value of sigmoid(phi) for some phi that we wish to know\n",
    "        the gradient of.\n",
    "    \"\"\"\n",
    "    return (x * (1 - x))\n",
    "    \n",
    "def relu(phi):\n",
    "    \"\"\"Rectified linear transfer function (ReLU).\n",
    "    \n",
    "    phi - A matrix of weighted inputs i.e. np.dot(W, X).\n",
    "    \"\"\"\n",
    "    return phi * (phi > 0.0)\n",
    "\n",
    "def grad_relu(x):\n",
    "    \"\"\"Calculates the gradient of the relu function at point x.\n",
    "    \n",
    "    x - The value of relu(phi) for some phi that we wish to know\n",
    "    the gradient of.\"\"\"\n",
    "    return 1.0 * (x > 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO - implement a softmax transfer function.\n",
    "def softmax(phi):\n",
    "    ret = np.zeros(shape=phi.shape)\n",
    "    for x in range(0, phi.shape[0]):\n",
    "        e_x = np.exp(phi[x,:] - np.max(phi[x,:]))\n",
    "        ret[x,:] = (e_x / e_x.sum())\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def grad_softmax(phi):\n",
    "    \"\"\"The gradient of the softmax is phi * (1 - phi) on the\n",
    "    diagonals, and phi * (0 - phi) on the off-diagonals.\n",
    "    \"\"\"\n",
    "    ret = np.zeros(shape=phi.shape)\n",
    "    for i in range(ret.shape[0]):\n",
    "        for j in range(ret.shape[1]):\n",
    "            if i == j:\n",
    "                ret[i, j] = phi[i, j] * (1 - phi[i, j])\n",
    "            else:\n",
    "                ret[i, j] = -1 * phi[i, j] * phi[i, j]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(X, ndim):\n",
    "    \"\"\"Transforms a vector of real valued targets to a one-hot\n",
    "    target matrix.\n",
    "    \"\"\"\n",
    "    out = np.zeros(shape=(X.shape[0], ndim))\n",
    "    for i in range(0, X.shape[0]):\n",
    "        row = np.zeros(shape=(1, ndim))\n",
    "        row[0, X[i]] = 1\n",
    "        out[i] = row\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64) (1797, 10)\n",
      "0.0 16.0\n"
     ]
    }
   ],
   "source": [
    "# Load the sklearn digits data set.\n",
    "digits = ds.load_digits()\n",
    "inputX = digits.data\n",
    "targ = digits.target\n",
    "\n",
    "# Note that targ is currently a vector, but we want a n x 10 matrix,\n",
    "# and so we reshape and then squeeze it into a one-hot distribution.\n",
    "targ = np.reshape(targ, (len(targ), 1))\n",
    "targ = one_hot(targ, ndim=10)\n",
    "\n",
    "print(inputX.shape, targ.shape)\n",
    "print(inputX.min(), inputX.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function we're climbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_goodness(Y, targets):\n",
    "    \"\"\"Often this is called the \"Loss\" or the \"Cost function\" (and \n",
    "    given a minus sign accordingly).\n",
    "    \n",
    "    Y -\n",
    "    targets -\n",
    "    \n",
    "    returns good_vec.sum() -\n",
    "            good_vec -\n",
    "            dgood -\n",
    "    \"\"\"\n",
    "    error = targets - Y\n",
    "    \n",
    "    # Inverted parabola centered on the target outputs.\n",
    "    good_vec = -0.5 * np.power(error, 2.0)\n",
    "    \n",
    "    # dGood_vec is the (direction? delta?) of something - if output\n",
    "    # is too low, it will be positive.\n",
    "    dgood = error \n",
    "    \n",
    "    return good_vec.sum(), good_vec, dgood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the network's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are this many neurons in each layer:  [64, 15, 15, 10]\n"
     ]
    }
   ],
   "source": [
    "# We have n examples from our inputX data. Each example has inputX.shape[1]\n",
    "# dimensions, and so we need inputX.shape[1] neurons in our input layer.\n",
    "# There are targ.shape[1] different output dimensions, and so we need\n",
    "# targ.shape[1] neurons in our output layer.\n",
    "input_dimensions = inputX.shape[1]\n",
    "output_dimensions = 10\n",
    "\n",
    "architecture = [input_dimensions, 15, 15, output_dimensions]\n",
    "\n",
    "print(\"There are this many neurons in each layer: \", architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 activations have shape (1797, 64)\n",
      "layer 1 activations have shape (1797, 15)\n",
      "layer 2 activations have shape (1797, 15)\n",
      "layer 3 activations have shape (1797, 10)\n"
     ]
    }
   ],
   "source": [
    "# X is going to be a list giving the activations of successive layers. \n",
    "# Each element in X is a matrix, whose columns are the neurons in the\n",
    "# layer corresponding to the elements index within X. Each row in the\n",
    "# matrix corresponds to a training item, so all the matrices in X will\n",
    "# have the same number of rows.\n",
    "X = [inputX]\n",
    "n = inputX.shape[0] # The number of examples that we have.\n",
    "\n",
    "for L in range(1, len(architecture)):\n",
    "    X.append(np.zeros(shape=(n, architecture[L]), dtype=float))\n",
    "\n",
    "for L in range(len(architecture)): \n",
    "    print(\"layer\", L, \"activations have shape\", X[L].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 weights have shape ()\n",
      "layer 1 weights have shape (15, 64)\n",
      "layer 2 weights have shape (15, 15)\n",
      "layer 3 weights have shape (10, 15)\n"
     ]
    }
   ],
   "source": [
    "# Let's index weight layer by the layer they're *going* towards.\n",
    "\n",
    "# Initialise the zero'th weight layers. W is a list of matrices. The element\n",
    "# at index i has the same number of rows as the number of columns in X[i]. i.e.\n",
    "# there is one row for each neuron in the layer that the weights are *going*\n",
    "# towards. Similarly, there is a column for each neuron in the layer that the\n",
    "# weights are *coming* from.\n",
    "W  = [np.array(None)]\n",
    "dW = [np.array(None)]\n",
    "\n",
    "init_weights_scale = 0.1  # 1 / np.sqrt((X[L].shape()).max())\n",
    "\n",
    "for layer in range(1, len(X)):\n",
    "    # There is a weight from each neuron in the previous layer to each neuron\n",
    "    # in the current layer.\n",
    "    in_dimension = X[layer - 1].shape[1]\n",
    "    out_dimension = X[layer].shape[1]\n",
    "    \n",
    "    W.append(init_weights_scale * rng.normal(0, 1, size=(out_dimension, in_dimension)))\n",
    "    \n",
    "    # The change in weights is initially zero, although we want to maintain\n",
    "    # the dimensionality of the weights matrix that we just constructed.\n",
    "    dW.append(0.0 * np.copy(W[layer]))\n",
    "\n",
    "for L in range(len(W)):\n",
    "    print(\"layer\", L, \"weights have shape\", W[L].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward_pass(X, W):\n",
    "    \"\"\"Takes the inputs to each layer, evaluates them with the \n",
    "    corresponding weights and then calculates the activation of\n",
    "    each neuron using the sigmoid function. No learning is done\n",
    "    at this stage, only evaluation of parameters.\n",
    "    \n",
    "    X - A list of matrices describing the inputs to each layer. The\n",
    "        inputs to the first layer (the input layer) is X[0]. In\n",
    "        general, the input to layer i is X[i - 1].\n",
    "    W - List of matrices describing the weights between each layer.\n",
    "        The weights *going* to layer i are indexed by W[i].\n",
    "        \n",
    "    returns X - the input X with new activations.\n",
    "    \"\"\"\n",
    "    for layer in range(1, len(X)):\n",
    "        # Grab the inputs to this layer, and transpose so that we\n",
    "        # can take the dot product of them with the corresponding\n",
    "        # weights.\n",
    "        inputs = X[layer - 1].transpose()\n",
    "        weighted_inputs = np.dot(W[layer], inputs).transpose()\n",
    "        \n",
    "        # The activations (outputs) of this layer are defined by the\n",
    "        # transfer function.\n",
    "        if layer < len(X) - 1:\n",
    "            X[layer] = sigmoid(weighted_inputs)\n",
    "        else:\n",
    "            # Perform softmax across final layer.\n",
    "            X[layer] = softmax(weighted_inputs)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def backward_pass(X, W, dW, targets):\n",
    "    \"\"\"Evaluates the error of the model, based on the calc_goodness\n",
    "    function and determines the direction and the magnitude of the\n",
    "    weight change needed to optimise.\n",
    "    \n",
    "    X - A list of matrices describing the inputs to each layer. The\n",
    "        inputs to the first layer (the input layer) is X[0]. In\n",
    "        general, the input to layer i is X[i - 1].\n",
    "    W - List of matrices describing the weights between each layer.\n",
    "        The weights *going* to layer i are indexed by W[i].\n",
    "    dW - A list of matrices containing the deltas to each weight layer.\n",
    "    targets - An n x 1 matrix containing the target class for each\n",
    "              example.\n",
    "    \n",
    "    returns dW -\n",
    "    \"\"\"\n",
    "    good_sum, good_vec, dgood = calc_goodness(X[-1], targets)\n",
    "    epsilon = dgood\n",
    "    npats = X[0].shape[0]\n",
    "    \n",
    "    # Then every other layer.\n",
    "    for layer in range(len(X) - 1, 0, -1):\n",
    "        if layer < len(X) - 1:\n",
    "            psi = epsilon * grad_sigmoid(X[layer]) # Element-wise multiply.\n",
    "        else:\n",
    "            psi = epsilon * grad_softmax(X[layer])\n",
    "        n1 = X[layer - 1].shape[1]\n",
    "        n2 = psi.shape[1]\n",
    "        A = np.tile(X[layer - 1], n2).reshape(npats, n2, n1)\n",
    "        B = np.repeat(psi, n1).reshape(npats, n2, n1)\n",
    "        dW[layer] = (A * B).sum(0) # Outer product multiply.\n",
    "        epsilon = np.dot(psi, W[layer]) # Inner product multiply.\n",
    "        \n",
    "    return dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = forward_pass(X, W)\n",
    "dW = backward_pass(X, W, dW, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkgrad(dW, X, W, targets):\n",
    "    \"\"\"Calculates the gradient directly, via pertubations to every weight.\n",
    "    This is completely daft in practical terms, but is very useful for debugging\n",
    "    as it tells us whether the backprop of errors is returning the true gradient.\n",
    "    \n",
    "    dW -\n",
    "    X -\n",
    "    W -\n",
    "    targets -\n",
    "    \n",
    "    returns None\n",
    "    \"\"\"\n",
    "    epsilon = 0.0001\n",
    "    \n",
    "    dW_test = [np.array(None)]\n",
    "    for L in range(1,len(W)):\n",
    "        dW_test.append(0.0*np.copy(W[L]))\n",
    "    \n",
    "    X = forward_pass(X, W)\n",
    "    base_good, tmp1, tmp2 = calc_goodness(X[-1], targets)\n",
    "    \n",
    "    for layer in range(1, len(X)):\n",
    "        # For each destination node.\n",
    "        for j in range(W[layer].shape[0]):\n",
    "            # For each origin node.\n",
    "            for i in range(W[layer].shape[1]):\n",
    "                # Perturb the weight from (layer - 1, i) -> (layer, j).\n",
    "                (W[layer])[j, i] += epsilon\n",
    "                # Compute and store the empirical gradient estimate.\n",
    "                X = forward_pass(X, W)\n",
    "                tmp_good, tmp1, tmp2 = calc_goodness(X[-1], targets)\n",
    "                (dW_test[layer])[j, i] = (tmp_good - base_good) / epsilon                \n",
    "                # Unperturb the weight.\n",
    "                (W[layer])[j, i] -= epsilon\n",
    "                \n",
    "    # Print the results for analysis.\n",
    "    for L in range(1, len(X)):\n",
    "        print ('-------------- layer %d --------------' %(L))\n",
    "        print ('calculated gradients:')\n",
    "        print (dW[L])\n",
    "        print ('empirical gradients:')\n",
    "        print (dW_test[L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- layer 1 --------------\n",
      "calculated gradients:\n",
      "[[ 0.    0.    0.02  0.02  0.01  0.02  0.01 -0.   -0.    0.01  0.03  0.\n",
      "   0.01  0.02  0.   -0.   -0.    0.01  0.02 -0.01 -0.01 -0.   -0.   -0.   -0.\n",
      "   0.01  0.02  0.   -0.01 -0.   -0.   -0.    0.   -0.   -0.   -0.02 -0.03\n",
      "   0.    0.01  0.   -0.   -0.   -0.01 -0.03 -0.02  0.01  0.02  0.   -0.    0.\n",
      "   0.01 -0.   -0.    0.02  0.01 -0.   -0.    0.    0.02  0.02  0.01  0.01\n",
      "  -0.   -0.  ]\n",
      " [ 0.   -0.01 -0.05 -0.02 -0.04 -0.08 -0.03 -0.    0.   -0.01 -0.05 -0.01\n",
      "   0.01  0.   -0.01 -0.    0.   -0.03 -0.05  0.02  0.06  0.05  0.01  0.    0.\n",
      "  -0.04 -0.07 -0.01  0.02  0.01 -0.    0.    0.   -0.02 -0.03  0.02  0.\n",
      "  -0.02 -0.01  0.    0.    0.    0.04  0.04 -0.02 -0.03  0.01  0.    0.   -0.\n",
      "   0.02  0.01 -0.04  0.    0.03  0.    0.   -0.01 -0.05 -0.03  0.03  0.06\n",
      "   0.03  0.  ]\n",
      " [ 0.    0.    0.01  0.04  0.04  0.03  0.01  0.   -0.   -0.    0.02  0.05\n",
      "   0.04  0.02  0.    0.    0.   -0.    0.01  0.04  0.02 -0.   -0.   -0.    0.\n",
      "   0.01  0.03  0.05  0.03 -0.   -0.   -0.    0.    0.01  0.03  0.04  0.04\n",
      "   0.02  0.    0.   -0.    0.    0.02  0.01  0.03  0.03  0.01 -0.   -0.   -0.\n",
      "   0.02  0.03  0.03  0.02 -0.    0.   -0.    0.    0.02  0.04  0.04  0.01\n",
      "  -0.    0.  ]\n",
      " [ 0.    0.   -0.   -0.    0.    0.    0.   -0.    0.   -0.   -0.    0.    0.\n",
      "   0.    0.   -0.   -0.   -0.    0.    0.    0.    0.    0.   -0.    0.    0.\n",
      "   0.    0.    0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.   -0.    0.    0.   -0.    0.    0.    0.   -0.   -0.   -0.   -0.   -0.\n",
      "   0.    0.    0.   -0.   -0.   -0.   -0.   -0.    0.    0.   -0.   -0.  ]\n",
      " [ 0.    0.    0.    0.01  0.02  0.01 -0.   -0.    0.    0.    0.01  0.01\n",
      "   0.    0.02  0.01 -0.    0.    0.    0.    0.    0.01  0.01  0.    0.    0.\n",
      "  -0.    0.    0.01  0.01 -0.   -0.    0.    0.    0.    0.01  0.02  0.03\n",
      "   0.   -0.01  0.    0.    0.    0.02  0.02  0.02  0.01 -0.01 -0.   -0.    0.\n",
      "   0.01  0.01  0.01  0.01 -0.   -0.   -0.    0.    0.01  0.02  0.01  0.   -0.\n",
      "  -0.  ]\n",
      " [ 0.   -0.   -0.   -0.   -0.01 -0.01 -0.    0.   -0.    0.   -0.   -0.01\n",
      "  -0.01 -0.01  0.    0.    0.   -0.   -0.   -0.01 -0.01  0.    0.    0.    0.\n",
      "  -0.   -0.01 -0.01 -0.01  0.01  0.01  0.    0.    0.   -0.01 -0.01 -0.01\n",
      "   0.    0.    0.    0.   -0.   -0.01 -0.01 -0.01 -0.    0.    0.    0.    0.\n",
      "  -0.01 -0.01 -0.01 -0.    0.    0.    0.   -0.   -0.   -0.01 -0.01  0.    0.\n",
      "   0.  ]\n",
      " [ 0.    0.    0.    0.    0.   -0.    0.    0.   -0.    0.    0.    0.    0.\n",
      "   0.    0.    0.   -0.    0.    0.   -0.   -0.    0.    0.    0.   -0.   -0.\n",
      "  -0.   -0.    0.    0.   -0.    0.    0.   -0.   -0.   -0.   -0.   -0.    0.\n",
      "   0.    0.   -0.   -0.   -0.   -0.   -0.    0.    0.    0.    0.    0.    0.\n",
      "  -0.   -0.    0.    0.    0.    0.    0.    0.   -0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.04  0.06  0.04  0.05  0.02 -0.   -0.    0.02  0.08  0.02\n",
      "   0.01  0.04  0.01 -0.   -0.    0.03  0.06 -0.03 -0.04  0.   -0.01 -0.   -0.\n",
      "   0.03  0.05  0.01 -0.01  0.    0.   -0.    0.   -0.    0.01 -0.01 -0.03\n",
      "   0.02  0.02  0.   -0.   -0.01 -0.01 -0.05 -0.05  0.02  0.04  0.   -0.   -0.\n",
      "   0.03  0.02 -0.01  0.04  0.02 -0.   -0.    0.    0.05  0.06  0.01  0.01\n",
      "  -0.01 -0.01]\n",
      " [ 0.    0.    0.03  0.05  0.06  0.04  0.01  0.    0.    0.01  0.04  0.03\n",
      "   0.06  0.07  0.01  0.    0.   -0.   -0.02  0.01  0.07  0.06  0.01  0.   -0.\n",
      "  -0.01 -0.04  0.03  0.07  0.03  0.   -0.    0.   -0.01 -0.01  0.04  0.06\n",
      "   0.03  0.01  0.   -0.   -0.    0.01  0.02  0.03  0.03  0.01 -0.   -0.    0.\n",
      "   0.02  0.03  0.03  0.03  0.    0.   -0.    0.    0.03  0.05  0.03  0.02\n",
      "   0.    0.  ]\n",
      " [ 0.    0.    0.02 -0.02 -0.01  0.02  0.02 -0.   -0.    0.01  0.01 -0.03\n",
      "  -0.03 -0.03 -0.   -0.   -0.    0.02  0.02 -0.02 -0.04 -0.05 -0.01  0.   -0.\n",
      "   0.01  0.02  0.01 -0.01 -0.03 -0.02  0.    0.   -0.01 -0.04 -0.05 -0.05\n",
      "  -0.02 -0.01  0.    0.   -0.01 -0.06 -0.05 -0.03 -0.01 -0.01 -0.   -0.    0.\n",
      "  -0.02 -0.05 -0.   -0.01 -0.02 -0.   -0.    0.    0.02 -0.01 -0.02 -0.04\n",
      "  -0.01 -0.  ]\n",
      " [ 0.    0.    0.01  0.03  0.02 -0.01 -0.   -0.   -0.    0.01  0.06  0.03\n",
      "   0.    0.01 -0.   -0.   -0.    0.02  0.09 -0.02 -0.05  0.03  0.01 -0.   -0.\n",
      "   0.02  0.06 -0.03 -0.05  0.03  0.02 -0.    0.    0.02  0.04 -0.03 -0.05\n",
      "   0.04  0.03  0.   -0.    0.01  0.07 -0.02 -0.06  0.05  0.06  0.   -0.    0.\n",
      "   0.07  0.02 -0.02  0.08  0.06 -0.    0.    0.    0.01  0.03  0.05  0.07\n",
      "   0.02 -0.01]\n",
      " [ 0.    0.    0.01  0.03  0.05  0.04  0.02  0.   -0.    0.    0.02  0.05\n",
      "   0.05  0.03  0.01  0.    0.    0.    0.03  0.04  0.03  0.02  0.    0.    0.\n",
      "   0.01  0.04  0.04  0.04  0.03  0.01  0.    0.    0.02  0.05  0.05  0.06\n",
      "   0.04  0.01  0.    0.    0.01  0.02  0.05  0.06  0.02  0.   -0.    0.    0.\n",
      "   0.    0.04  0.04  0.   -0.   -0.   -0.    0.    0.02  0.03  0.02  0.01\n",
      "  -0.   -0.  ]\n",
      " [ 0.   -0.    0.01  0.04  0.06  0.03  0.01  0.    0.   -0.    0.03  0.05\n",
      "   0.03  0.03  0.01  0.    0.    0.    0.04  0.04  0.01  0.03  0.01  0.    0.\n",
      "   0.02  0.06  0.04  0.04  0.04  0.02  0.    0.    0.02  0.06  0.05  0.06\n",
      "   0.05  0.01  0.    0.    0.01  0.03  0.04  0.06  0.03  0.   -0.    0.    0.\n",
      "   0.01  0.03  0.04  0.   -0.01  0.   -0.   -0.    0.01  0.04  0.03 -0.01\n",
      "  -0.01 -0.  ]\n",
      " [ 0.    0.    0.03  0.05  0.05  0.05  0.01  0.    0.    0.01  0.05  0.03\n",
      "   0.03  0.03  0.01  0.    0.    0.01  0.02  0.    0.02  0.02  0.   -0.   -0.\n",
      "   0.01  0.02  0.03  0.04  0.02  0.01 -0.    0.    0.    0.02  0.04  0.04\n",
      "   0.03  0.01  0.   -0.   -0.   -0.    0.02  0.03  0.02  0.   -0.   -0.    0.\n",
      "   0.01  0.03  0.02  0.01 -0.   -0.   -0.    0.    0.04  0.05  0.01 -0.01\n",
      "  -0.    0.  ]\n",
      " [ 0.   -0.   -0.01 -0.01 -0.01 -0.01 -0.   -0.   -0.   -0.01 -0.01 -0.01\n",
      "   0.    0.   -0.    0.    0.   -0.01 -0.02 -0.    0.01  0.01  0.   -0.   -0.\n",
      "  -0.01 -0.02 -0.01  0.    0.01  0.   -0.    0.   -0.   -0.   -0.   -0.    0.\n",
      "   0.    0.   -0.   -0.    0.   -0.   -0.01 -0.   -0.    0.   -0.   -0.   -0.\n",
      "  -0.01 -0.01 -0.   -0.    0.    0.   -0.   -0.01 -0.01 -0.    0.    0.    0.  ]]\n",
      "empirical gradients:\n",
      "[[ 0.   -0.02 -0.19 -0.08 -0.08 -0.22 -0.07  0.01  0.   -0.07 -0.25  0.02\n",
      "  -0.07 -0.14 -0.03  0.01  0.   -0.12 -0.14  0.09  0.13  0.04  0.05  0.01\n",
      "   0.   -0.08 -0.12 -0.06  0.13  0.04  0.03  0.    0.    0.07  0.09  0.22\n",
      "   0.28 -0.   -0.05  0.    0.    0.06  0.2   0.29  0.24 -0.07 -0.14  0.    0.\n",
      "  -0.   -0.06  0.09  0.08 -0.16 -0.04  0.01  0.   -0.02 -0.2  -0.11 -0.02\n",
      "  -0.03  0.05  0.02]\n",
      " [ 0.    0.04  0.43  0.28  0.38  0.65  0.28  0.01 -0.    0.1   0.54  0.15\n",
      "  -0.01  0.12  0.08  0.   -0.    0.23  0.54 -0.17 -0.52 -0.3  -0.03 -0.   -0.\n",
      "   0.38  0.66  0.08 -0.22  0.06  0.1  -0.    0.    0.2   0.32 -0.3  -0.09\n",
      "   0.32  0.17  0.   -0.    0.02 -0.32 -0.43  0.16  0.36 -0.01 -0.   -0.    0.\n",
      "  -0.1  -0.03  0.4   0.05 -0.3  -0.02 -0.    0.04  0.47  0.39 -0.17 -0.54\n",
      "  -0.29 -0.04]\n",
      " [ 0.    0.   -0.1  -0.33 -0.32 -0.26 -0.08 -0.    0.    0.05 -0.09 -0.33\n",
      "  -0.27 -0.18 -0.03  0.   -0.    0.04 -0.01 -0.34 -0.2   0.03  0.05  0.   -0.\n",
      "  -0.05 -0.23 -0.47 -0.28  0.03  0.05  0.    0.   -0.02 -0.26 -0.32 -0.33\n",
      "  -0.19 -0.03  0.    0.    0.02 -0.05 -0.04 -0.2  -0.23 -0.09  0.    0.\n",
      "   0.02 -0.05 -0.18 -0.22 -0.15  0.03 -0.01  0.    0.   -0.11 -0.34 -0.29\n",
      "  -0.03  0.08 -0.03]\n",
      " [ 0.   -0.    0.    0.01 -0.02 -0.04 -0.01  0.   -0.    0.    0.01 -0.01\n",
      "  -0.02 -0.03 -0.01  0.    0.   -0.   -0.02 -0.04 -0.02 -0.03 -0.01  0.   -0.\n",
      "  -0.   -0.02 -0.02 -0.01 -0.03 -0.   -0.    0.   -0.   -0.01 -0.   -0.02\n",
      "  -0.04 -0.    0.    0.   -0.   -0.    0.01 -0.02 -0.04 -0.01  0.    0.    0.\n",
      "   0.    0.01 -0.02 -0.04 -0.01  0.    0.   -0.    0.    0.01 -0.01 -0.02\n",
      "   0.01  0.01]\n",
      " [ 0.   -0.01 -0.08 -0.19 -0.21 -0.11  0.    0.   -0.   -0.04 -0.17 -0.14\n",
      "  -0.07 -0.21 -0.06  0.   -0.   -0.02 -0.04 -0.02 -0.08 -0.16 -0.03 -0.   -0.\n",
      "   0.01 -0.01 -0.11 -0.19 -0.01  0.04 -0.    0.   -0.02 -0.1  -0.26 -0.33\n",
      "  -0.03  0.06  0.   -0.   -0.02 -0.22 -0.18 -0.19 -0.16  0.03  0.    0.\n",
      "  -0.01 -0.17 -0.12 -0.1  -0.13 -0.    0.    0.   -0.   -0.09 -0.22 -0.15\n",
      "  -0.05  0.01  0.  ]\n",
      " [ 0.    0.    0.03  0.06  0.11  0.1   0.   -0.01  0.   -0.    0.04  0.08\n",
      "   0.1   0.1   0.   -0.01 -0.    0.02  0.06  0.12  0.07  0.01 -0.03 -0.01\n",
      "  -0.    0.02  0.08  0.15  0.08 -0.05 -0.06 -0.    0.   -0.01  0.05  0.09\n",
      "   0.09 -0.01 -0.02  0.   -0.    0.01  0.08  0.05  0.09  0.08  0.   -0.   -0.\n",
      "   0.    0.08  0.06  0.09  0.07 -0.02 -0.   -0.    0.    0.02  0.08  0.11\n",
      "   0.02 -0.03 -0.01]\n",
      " [ 0.   -0.   -0.02 -0.04 -0.04  0.   -0.   -0.    0.   -0.01 -0.04 -0.04\n",
      "  -0.03 -0.01 -0.   -0.    0.   -0.   -0.02 -0.01 -0.02 -0.03 -0.01 -0.    0.\n",
      "   0.   -0.01 -0.03 -0.03 -0.05 -0.02 -0.    0.   -0.    0.   -0.   -0.\n",
      "  -0.04 -0.01  0.   -0.   -0.01 -0.   -0.02 -0.02 -0.02 -0.01 -0.   -0.   -0.\n",
      "  -0.02 -0.02 -0.03 -0.03 -0.02 -0.   -0.   -0.   -0.02 -0.04 -0.04 -0.02\n",
      "  -0.01 -0.01]\n",
      " [ 0.   -0.03 -0.35 -0.52 -0.35 -0.48 -0.18  0.    0.   -0.12 -0.73 -0.24\n",
      "  -0.11 -0.43 -0.08  0.01  0.   -0.3  -0.66  0.26  0.39 -0.08  0.02  0.01\n",
      "   0.   -0.29 -0.52 -0.11  0.18 -0.04 -0.08  0.    0.   -0.01 -0.11  0.19\n",
      "   0.34 -0.17 -0.23  0.    0.01  0.13  0.09  0.53  0.48 -0.23 -0.35 -0.    0.\n",
      "   0.01 -0.33 -0.14  0.1  -0.39 -0.11  0.02  0.   -0.03 -0.39 -0.56 -0.13\n",
      "  -0.07  0.14  0.09]\n",
      " [ 0.   -0.01 -0.31 -0.5  -0.6  -0.44 -0.09 -0.02 -0.   -0.14 -0.4  -0.21\n",
      "  -0.56 -0.73 -0.15 -0.01 -0.   -0.    0.27  0.01 -0.76 -0.56 -0.05 -0.    0.\n",
      "   0.15  0.43 -0.31 -0.78 -0.27 -0.    0.    0.    0.14  0.23 -0.28 -0.61\n",
      "  -0.32 -0.03  0.    0.    0.05  0.15 -0.08 -0.28 -0.26 -0.02  0.01  0.\n",
      "  -0.01 -0.1  -0.22 -0.22 -0.24 -0.01  0.    0.   -0.01 -0.37 -0.46 -0.23\n",
      "  -0.1   0.03 -0.01]\n",
      " [ 0.   -0.02 -0.16  0.23  0.11 -0.15 -0.13  0.01  0.   -0.1  -0.05  0.27\n",
      "   0.27  0.31  0.03  0.    0.   -0.12 -0.11  0.12  0.3   0.45  0.09 -0.    0.\n",
      "  -0.09 -0.1  -0.08  0.1   0.22  0.15 -0.    0.    0.06  0.37  0.42  0.4\n",
      "   0.16  0.08  0.   -0.    0.07  0.54  0.44  0.22  0.05  0.08  0.    0.\n",
      "  -0.03  0.21  0.44  0.03  0.13  0.18  0.02  0.   -0.03 -0.15  0.09  0.14\n",
      "   0.31  0.13  0.04]\n",
      " [ 0.   -0.01 -0.16 -0.64 -0.44  0.1   0.06  0.    0.   -0.05 -0.87 -0.75\n",
      "  -0.36 -0.38  0.02  0.01  0.   -0.27 -1.31 -0.09  0.47 -0.56 -0.19  0.01\n",
      "   0.   -0.35 -1.03  0.29  0.6  -0.45 -0.38  0.    0.   -0.37 -0.86  0.16\n",
      "   0.45 -0.57 -0.49  0.    0.   -0.21 -1.17 -0.02  0.52 -0.84 -0.77 -0.01\n",
      "   0.   -0.06 -1.14 -0.59 -0.15 -1.16 -0.71  0.03 -0.   -0.01 -0.16 -0.62\n",
      "  -0.92 -0.91 -0.25  0.1 ]\n",
      " [ 0.   -0.01 -0.11 -0.28 -0.51 -0.42 -0.19 -0.02  0.   -0.02 -0.15 -0.43\n",
      "  -0.41 -0.26 -0.13 -0.01 -0.   -0.01 -0.2  -0.38 -0.3  -0.16 -0.04 -0.   -0.\n",
      "  -0.09 -0.36 -0.42 -0.46 -0.33 -0.12 -0.    0.   -0.15 -0.43 -0.53 -0.65\n",
      "  -0.43 -0.12  0.   -0.   -0.1  -0.18 -0.52 -0.62 -0.19  0.02  0.   -0.\n",
      "  -0.01  0.04 -0.37 -0.37  0.03  0.04  0.    0.   -0.02 -0.15 -0.27 -0.18\n",
      "  -0.04  0.02  0.  ]\n",
      " [ 0.    0.01 -0.06 -0.37 -0.58 -0.33 -0.1  -0.01 -0.    0.03 -0.23 -0.5\n",
      "  -0.35 -0.35 -0.12 -0.01 -0.   -0.02 -0.37 -0.35 -0.18 -0.34 -0.13 -0.01\n",
      "  -0.   -0.17 -0.52 -0.4  -0.38 -0.46 -0.24 -0.    0.   -0.24 -0.6  -0.53\n",
      "  -0.6  -0.5  -0.17  0.   -0.   -0.14 -0.34 -0.38 -0.61 -0.34 -0.01  0.   -0.\n",
      "  -0.01 -0.06 -0.28 -0.42 -0.01  0.12  0.    0.    0.01 -0.08 -0.4  -0.27\n",
      "   0.1   0.1   0.  ]\n",
      " [ 0.   -0.03 -0.32 -0.46 -0.49 -0.42 -0.11 -0.   -0.   -0.14 -0.46 -0.31\n",
      "  -0.33 -0.35 -0.07 -0.   -0.   -0.12 -0.17 -0.01 -0.24 -0.21 -0.    0.    0.\n",
      "  -0.06 -0.15 -0.32 -0.43 -0.23 -0.07  0.    0.   -0.   -0.2  -0.36 -0.4\n",
      "  -0.27 -0.08  0.    0.    0.01  0.01 -0.22 -0.26 -0.17 -0.02  0.    0.\n",
      "  -0.02 -0.08 -0.3  -0.22 -0.09  0.01  0.    0.   -0.02 -0.37 -0.44 -0.1\n",
      "   0.03  0.02 -0.  ]\n",
      " [ 0.    0.01  0.04  0.02  0.01  0.02  0.01  0.    0.    0.04  0.06  0.04\n",
      "  -0.03 -0.05 -0.01 -0.   -0.    0.08  0.15  0.03 -0.07 -0.07 -0.    0.    0.\n",
      "   0.07  0.11  0.02 -0.06 -0.08 -0.05  0.    0.    0.02  0.02  0.01 -0.01\n",
      "  -0.02 -0.02  0.    0.    0.   -0.01 -0.01  0.04  0.02  0.   -0.    0.\n",
      "   0.01  0.01  0.02  0.07  0.01  0.    0.    0.    0.01  0.04  0.05  0.02\n",
      "   0.    0.    0.  ]]\n",
      "-------------- layer 2 --------------\n",
      "calculated gradients:\n",
      "[[ 0.02 -0.01 -0.05  0.    0.01  0.   -0.01  0.07 -0.04  0.   -0.01  0.03\n",
      "  -0.03  0.02  0.01]\n",
      " [ 0.02  0.03 -0.03  0.01  0.   -0.01  0.01  0.    0.01 -0.01 -0.01  0.04\n",
      "  -0.04  0.01  0.01]\n",
      " [ 0.05  0.    0.04  0.01 -0.08 -0.02  0.02 -0.04  0.02  0.    0.04  0.01\n",
      "   0.02  0.02  0.01]\n",
      " [-0.01 -0.04  0.01  0.03  0.03  0.03  0.04  0.02  0.02  0.03  0.01  0.02\n",
      "   0.03  0.01  0.03]\n",
      " [ 0.03 -0.02 -0.01  0.01  0.01 -0.06  0.01 -0.03  0.01 -0.04  0.03 -0.02\n",
      "   0.01  0.   -0.  ]\n",
      " [ 0.04  0.02 -0.06  0.04  0.05 -0.03  0.03  0.05  0.    0.02 -0.02  0.05\n",
      "  -0.03  0.05  0.04]\n",
      " [-0.04 -0.02  0.08  0.01 -0.02  0.06  0.01  0.    0.    0.02  0.   -0.01\n",
      "   0.05 -0.02 -0.  ]\n",
      " [ 0.    0.06  0.03  0.04 -0.02  0.03  0.05 -0.02  0.03  0.02  0.03  0.06\n",
      "  -0.05  0.03  0.04]\n",
      " [-0.03  0.01  0.01 -0.01  0.    0.02 -0.01 -0.01  0.02  0.    0.   -0.02\n",
      "  -0.01 -0.02 -0.01]\n",
      " [-0.02  0.   -0.02 -0.02  0.03 -0.01 -0.02 -0.02  0.01  0.   -0.02 -0.03\n",
      "  -0.   -0.02 -0.02]\n",
      " [ 0.06 -0.06 -0.03  0.04  0.   -0.01  0.04  0.04 -0.01  0.04  0.01  0.02\n",
      "   0.04  0.05  0.04]\n",
      " [ 0.02 -0.03  0.01 -0.01 -0.05  0.01 -0.   -0.02 -0.01 -0.01  0.03 -0.01\n",
      "   0.02 -0.   -0.  ]\n",
      " [ 0.06 -0.03 -0.01  0.04 -0.03 -0.02  0.04  0.05 -0.    0.01  0.02  0.06\n",
      "   0.02  0.04  0.04]\n",
      " [ 0.01  0.05 -0.01 -0.   -0.   -0.02 -0.01 -0.03  0.02 -0.01  0.   -0.01\n",
      "  -0.04  0.01 -0.01]\n",
      " [ 0.02  0.01 -0.    0.06  0.01  0.02  0.06  0.03 -0.01  0.04  0.02  0.05\n",
      "  -0.03  0.06  0.06]]\n",
      "empirical gradients:\n",
      "[[-0.25  0.12  0.34 -0.12 -0.05 -0.13 -0.08 -0.7   0.42 -0.1   0.03 -0.39\n",
      "   0.2  -0.29 -0.22]\n",
      " [-0.28 -0.32  0.23 -0.23  0.04  0.11 -0.24 -0.03 -0.19 -0.02 -0.   -0.55\n",
      "   0.41 -0.24 -0.31]\n",
      " [-0.57 -0.05 -0.29 -0.09  0.79  0.37 -0.08  0.45 -0.25  0.   -0.37 -0.12\n",
      "  -0.15 -0.18 -0.1 ]\n",
      " [ 0.39  0.4  -0.05 -0.03 -0.32 -0.4  -0.14 -0.21 -0.06 -0.14  0.08  0.12\n",
      "  -0.25  0.18 -0.04]\n",
      " [-0.33  0.19  0.12 -0.1  -0.14  0.62 -0.09  0.33 -0.24  0.47 -0.35  0.17\n",
      "  -0.15 -0.08  0.  ]\n",
      " [-0.32 -0.31  0.47 -0.35 -0.42  0.26 -0.3  -0.32 -0.05 -0.27  0.2  -0.44\n",
      "   0.32 -0.47 -0.36]\n",
      " [ 0.6   0.2  -0.66  0.14  0.07 -0.56  0.06 -0.1   0.08 -0.13  0.14  0.24\n",
      "  -0.49  0.38  0.19]\n",
      " [-0.04 -0.63 -0.33 -0.43  0.26 -0.16 -0.49  0.27 -0.38 -0.23 -0.26 -0.6\n",
      "   0.59 -0.32 -0.46]\n",
      " [ 0.39 -0.07 -0.1   0.15 -0.05 -0.21  0.1   0.1  -0.19 -0.05  0.01  0.17\n",
      "   0.11  0.25  0.11]\n",
      " [ 0.05 -0.17  0.12 -0.17 -0.31  0.08 -0.19  0.03 -0.31 -0.34  0.14 -0.01\n",
      "   0.03 -0.13 -0.16]\n",
      " [-0.51  0.53  0.22 -0.33  0.03  0.04 -0.34 -0.4   0.13 -0.36 -0.09 -0.17\n",
      "  -0.36 -0.43 -0.36]\n",
      " [-0.2   0.4  -0.08  0.12  0.46 -0.09  0.09  0.15  0.22  0.17 -0.29  0.13\n",
      "  -0.15  0.05  0.07]\n",
      " [-0.62  0.19  0.06 -0.35  0.32  0.21 -0.36 -0.41 -0.04 -0.13 -0.18 -0.6\n",
      "  -0.13 -0.41 -0.43]\n",
      " [-0.12 -0.45  0.09  0.04  0.05  0.33  0.1   0.43 -0.14  0.05 -0.06  0.1\n",
      "   0.34 -0.09  0.07]\n",
      " [-0.21 -0.2  -0.06 -0.51 -0.04 -0.18 -0.52 -0.26  0.11 -0.39 -0.13 -0.46\n",
      "   0.27 -0.55 -0.5 ]]\n",
      "-------------- layer 3 --------------\n",
      "calculated gradients:\n",
      "[[-0.12 -0.09 -0.1  -0.11 -0.08 -0.12 -0.12 -0.11 -0.09 -0.08 -0.1  -0.08\n",
      "  -0.09 -0.09 -0.08]\n",
      " [ 0.22  0.13  0.16  0.18  0.14  0.17  0.13  0.15  0.12  0.15  0.17  0.14\n",
      "   0.16  0.13  0.13]\n",
      " [-0.02  0.04 -0.04 -0.02 -0.02  0.02 -0.   -0.06 -0.01 -0.01 -0.   -0.01\n",
      "  -0.   -0.02  0.01]\n",
      " [-0.07 -0.02 -0.07 -0.07 -0.07 -0.06 -0.05 -0.1  -0.07 -0.06 -0.05 -0.05\n",
      "  -0.05 -0.06 -0.05]\n",
      " [ 0.07 -0.    0.06  0.11  0.06  0.08  0.03  0.06  0.05  0.03  0.07  0.05\n",
      "   0.09  0.02 -0.  ]\n",
      " [ 0.27  0.35  0.31  0.26  0.25  0.39  0.46  0.39  0.36  0.31  0.35  0.26\n",
      "   0.24  0.35  0.33]\n",
      " [-0.03 -0.05 -0.    0.02 -0.04 -0.02 -0.03 -0.02 -0.02  0.02 -0.03  0.02\n",
      "  -0.02 -0.06 -0.05]\n",
      " [ 0.08 -0.    0.04  0.05  0.05  0.04  0.07  0.11  0.03 -0.03  0.02 -0.01\n",
      "   0.05  0.09  0.02]\n",
      " [ 0.13  0.12  0.12  0.12  0.1   0.14  0.14  0.16  0.1   0.11  0.12  0.09\n",
      "   0.11  0.13  0.11]\n",
      " [ 0.33  0.28  0.35  0.33  0.33  0.24  0.37  0.39  0.31  0.33  0.35  0.26\n",
      "   0.23  0.33  0.29]]\n",
      "empirical gradients:\n",
      "[[ 2.44  1.78  2.01  2.28  1.67  2.36  2.39  2.22  1.77  1.79  2.12  1.64\n",
      "   1.89  1.88  1.6 ]\n",
      " [-1.39 -0.57 -0.79 -0.96 -0.73 -0.85 -0.34 -0.6  -0.46 -0.78 -0.85 -0.75\n",
      "  -0.88 -0.56 -0.63]\n",
      " [ 0.78  0.13  0.97  0.79  0.74  0.43  0.69  1.27  0.66  0.56  0.61  0.52\n",
      "   0.54  0.78  0.4 ]\n",
      " [ 1.43  0.73  1.44  1.52  1.29  1.34  1.3   1.91  1.34  1.2   1.28  1.1\n",
      "   1.16  1.27  1.04]\n",
      " [-0.01  0.59  0.02 -0.42 -0.03 -0.17  0.48  0.14  0.1   0.34 -0.02  0.02\n",
      "  -0.31  0.46  0.58]\n",
      " [-1.58 -2.29 -1.88 -1.53 -1.48 -2.52 -2.99 -2.47 -2.34 -1.91 -2.18 -1.65\n",
      "  -1.48 -2.22 -2.15]\n",
      " [ 1.1   1.2   0.71  0.49  1.07  1.02  1.22  1.    0.83  0.4   1.15  0.32\n",
      "   0.83  1.34  1.15]\n",
      " [-0.19  0.71  0.2   0.22  0.    0.26  0.05 -0.33  0.27  0.95  0.49  0.69\n",
      "   0.12 -0.26  0.35]\n",
      " [-0.55 -0.6  -0.53 -0.42 -0.4  -0.61 -0.53 -0.72 -0.29 -0.47 -0.43 -0.37\n",
      "  -0.5  -0.58 -0.5 ]\n",
      " [-2.03 -1.68 -2.16 -1.99 -2.13 -1.26 -2.29 -2.42 -1.89 -2.07 -2.17 -1.52\n",
      "  -1.36 -2.11 -1.84]]\n"
     ]
    }
   ],
   "source": [
    "checkgrad(dW, X, W, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yay.\n",
    "The gradient seems to be right for the full MLP, so that's... progress!\n",
    "\n",
    "Let's try learning the problem then...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learn(X, W, dW, targets, learning_rate=0.01, momentum=0.1, num_steps=1):\n",
    "    # note dW and prev_change are of the same size as W - we'll make space for them first\n",
    "    times, vals = [], []\n",
    "    next_time = 0\n",
    "    \n",
    "    prev_change = [np.array(None)]\n",
    "    for L in range(1,len(X)):\n",
    "        prev_change.append(0.0 * np.copy(W[L]))\n",
    "    \n",
    "    # now for the learning iterations\n",
    "    for step in range(num_steps):\n",
    "        X = forward_pass(X,W)\n",
    "        \n",
    "        # this is just record-keeping.......\n",
    "        if step == next_time:\n",
    "            good_sum, good_vec, dgood = calc_goodness(X[-1], targets)\n",
    "            vals.append(good_sum)\n",
    "            times.append(step)\n",
    "            next_time = step + 10\n",
    "\n",
    "        dW = backward_pass(X, W, dW, targets)\n",
    "        for L in range(1,len(X)):\n",
    "            change =  (learning_rate * dW[L]) + (momentum * prev_change[L])\n",
    "            W[L] = W[L] + change\n",
    "            prev_change[L] = change\n",
    "\n",
    "\n",
    "    return W, times, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10f10d3c8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEACAYAAACgS0HpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsIkdXzhefAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ed6df98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W, times, vals = learn(X, W, dW, targ, learning_rate=0.01, momentum=0.5, num_steps=500)\n",
    "plt.plot(times, vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "This code never got around to properly working correctly. I believe that the problem lies with pushing the gradients back through the softmax function. As shown in the previous section, the gradient of the softmax function is equal to $y_i(1 - y_i)$ on the diagonals and $-y_iy_j$ on the off-diagonals. I believe that my implementation captures this, although something that is yet unidentified is fundamentally wrong (at least judging by the error graph produced above).\n",
    "\n",
    "__Sigmoids vs. Relus__\n",
    "\n",
    "In light of the strife outlined above, I didn't get to produce an analysis of whether sigmoids or relus result in a higher classification accuracy, or enable the neural net to be trained quicker in this particular application on the digits data set. \n",
    "\n",
    "Theoretically, since the relu function has a non-saturating gradient, the network using relus will converge orders of magnitude faster (due to the gradients of any activations being equal to 1, instead of arbitrarily small values as in the case of the sigmoid). Results in literature confirm this faster convergence.\n",
    "\n",
    "As for whether a network trained with sigmoids or relus will converge on a _better_ solution? That's a non-trivial question. Intuitively, a larger gradient means larger updates to each weight per cycle (this can be seen by the delta rule from part 2 of the assignment). This is great in the early training stages, although leaves open the possibility of 'skipping past' optima (or oscillating around optima) in the final stages of training. Because of this fact, a decaying momentum rate  seems like a good idea when training a network using relus as the magnitude of weight updates can then be decreased over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
