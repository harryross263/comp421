# Week 6 - several things this week!


## More about Reinforcement Learning
`(Tuesday: Marcus)`
* We continue with the material from last week in [RL with Values](https://github.com/garibaldu/comp421/blob/master/week5/lecture_RL_via_Values.pdf). Note I've added a [notebook demonstration of Value Iteration](https://github.com/garibaldu/comp421/blob/master/notebooks/demo_value_iteration.ipynb) there.
* Today I hope to also make mention of RL via policy gradient [RL via policy gradient](https://github.com/garibaldu/comp421/blob/master/week6/lecture_RL_via_policy_gradient.pdf). This will have to be brief - policy gradient is worth more time, but I leave this with you to explore (e.g. in the project) if you wish.
* For those wanting more: 
   * [Scholarpedia article on policy gradient methods](http://www.scholarpedia.org/article/Policy_gradient_methods)
   * [tutorial on deep RL](https://gym.openai.com/docs/rl)

## DeepArt
`(Tuesday: led by Linfeng and Yi)`
* this is an application
* here is the [paper](https://arxiv.org/pdf/1508.06576v2.pdf)
* (MF: I found [this](https://www.robots.ox.ac.uk/~vgg/rg/slides/weidi_rg.pdf) a useful summary too, and pointed me to this earlier paper that just looks at the procedure used for making of images from representations i.e. [inversion](http://arxiv.org/pdf/1412.0035v1.pdf) )

## Q & A
`(Friday: lab / tutorial session)`
* Q and A: email me questions by noon Thursday please.

1. bias weights - what's the point of them
1. some seed articles - food for thought:
   * http://ml.posthaven.com/machine-learning-done-wrong
   * http://lemoxo.com/when-machine-learning-goes-wrong/
   * http://www.informationweek.com/software/productivity-collaboration-apps/13-ways-machine-learning-can-steer-you-wrong/d/d-id/1326646?utm_content=buffer7f89b&utm_medium=social&utm_source=twitter%2Ecom&utm_campaign=buffer&image_number=13
1. will machine learners experience pain and pleasure - discuss!..

* also: autograd, and the second assignment (outline)
* also: the project to come - start thinking about what you might like to do

